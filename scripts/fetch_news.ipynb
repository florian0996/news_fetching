{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2f6198a-2b05-45fa-aaf3-3f24039516c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (5.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a91d248-5325-4126-8cec-8498f3ab80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import feedparser\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad76967a-60bc-4ab7-b69b-d7104b688649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG ==========\n",
    "NEWSAPI_KEY = \"186dd4ccd2234f6a89f850bf16effb06\"\n",
    "QUERY = \"fintech OR lending OR investment OR credit OR platform OR loan\"\n",
    "LANGUAGE = \"en\"\n",
    "PAGE_SIZE = 100\n",
    "\n",
    "RSS_FEEDS = {\n",
    "    \"Markets\": \"https://feeds.bloomberg.com/markets/news.rss\",\n",
    "    \"Politics\": \"https://feeds.bloomberg.com/politics/news.rss\",\n",
    "    \"Business\": \"https://feeds.bloomberg.com/business/news.rss\",\n",
    "    \"Technology\": \"https://feeds.bloomberg.com/technology/news.rss\",\n",
    "    \"Economics\": \"https://feeds.bloomberg.com/economics/news.rss\",\n",
    "    \"Industries\": \"https://feeds.bloomberg.com/industries/news.rss\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2db57e0-e91e-4cab-ad2b-ed9b4b937743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== NEWSAPI FETCH ==========\n",
    "def fetch_newsapi():\n",
    "    print(\"Fetching from NewsAPI...\")\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": QUERY,\n",
    "        \"language\": LANGUAGE,\n",
    "        \"pageSize\": PAGE_SIZE,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": NEWSAPI_KEY,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"NewsAPI error: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "    articles = response.json().get(\"articles\", [])\n",
    "    print(f\"→ NewsAPI: {len(articles)} articles fetched.\")\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            \"source\": f\"{a['source']['name']} [NewsAPI]\",\n",
    "            \"url\": a[\"url\"],\n",
    "            \"title\": a[\"title\"],\n",
    "            \"published_at\": a[\"publishedAt\"],\n",
    "            \"content\": a[\"content\"],\n",
    "            \"platforms_mentioned\": [],\n",
    "        }\n",
    "        for a in articles\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d65f73-9a6e-49e2-be1f-e02a7aa1b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== BLOOMBERG RSS FETCH ==========\n",
    "def fetch_bloomberg_rss():\n",
    "    print(\"Fetching Bloomberg RSS feeds...\")\n",
    "    all_articles = []\n",
    "    for name, feed_url in RSS_FEEDS.items():\n",
    "        feed = feedparser.parse(feed_url)\n",
    "        for entry in feed.entries:\n",
    "            content = getattr(entry, 'summary', entry.get('description', \"\"))\n",
    "            all_articles.append({\n",
    "                \"source\":           f\"Bloomberg - {name} [RSS]\",\n",
    "                \"url\":              entry.link,\n",
    "                \"title\":            entry.title,\n",
    "                \"published_at\":     entry.published if \"published\" in entry else \"\",\n",
    "                \"content\":          content,\n",
    "                \"platforms_mentioned\": [],\n",
    "            })\n",
    "    print(f\"→ Bloomberg RSS: {len(all_articles)} articles fetched.\")\n",
    "    return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c1cd47-ca83-492f-89c8-33c99dfb88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SEC FETCH ==========\n",
    "def fetch_sec_press_releases():\n",
    "    RSS_URL = \"https://www.sec.gov/news/pressreleases.rss\"\n",
    "    feed = feedparser.parse(RSS_URL)\n",
    "\n",
    "    entries = []\n",
    "    for e in feed.entries:\n",
    "        entries.append({\n",
    "            \"source\": \"SEC Press Releases [RSS]\",\n",
    "            \"url\":       e.link,\n",
    "            \"title\":     e.title,\n",
    "            \"published_at\": getattr(e, \"published\", \"\"),\n",
    "            \"content\":     e.get(\"summary\", \"\"),\n",
    "            \"platforms_mentioned\": [],\n",
    "        })\n",
    "\n",
    "    print(f\"→ SEC Press Releases: {len(entries)} fetched.\")\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58aa8b87-8942-40d5-8d85-bdf39ebf7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== GNEWS FETCH ==========\n",
    "def fetch_gnews_financial_times():\n",
    "    print(\"Fetching from GNews (lending and credit)...\")\n",
    "    api_key = \"c4f8fe7bbdaea71cd2ec22279906c40f\"\n",
    "    url = \"https://gnews.io/api/v4/search\"\n",
    "    params = {\n",
    "        \"q\": \"lending OR credit\",\n",
    "        \"in\": \"title,description\",\n",
    "        \"lang\": \"en\",\n",
    "        \"country\": \"us\",\n",
    "        \"max\": 100,\n",
    "        \"token\": api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"GNews error: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "    articles = response.json().get(\"articles\", [])\n",
    "    print(f\"→ GNews: {len(articles)} articles fetched.\")\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"source\": f\"{a.get('source', {}).get('name', 'N/A')} [GNews]\",\n",
    "            \"url\": a.get(\"url\", \"\"),\n",
    "            \"title\": a.get(\"title\", \"\"),\n",
    "            \"published_at\": a.get(\"publishedAt\", \"\"),\n",
    "            \"content\": a.get(\"description\", \"\"),\n",
    "            \"platforms_mentioned\": [],\n",
    "        }\n",
    "        for a in articles\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c353e96-0701-438e-ac37-b4549d05740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== INVESTING.COM RSS FETCH ==========\n",
    "def fetch_investing_rss():\n",
    "    print(\"Fetching Investing.com RSS feeds...\")\n",
    "    feeds = {\n",
    "        \"Investing.com (English) [RSS]\": \"https://www.investing.com/rss/news_25.rss?limit=20\",\n",
    "        \"Investing.com (German) [RSS]\": \"https://de.investing.com/rss/news_95.rss\"\n",
    "    }\n",
    "    articles = []\n",
    "    for label, feed_url in feeds.items():\n",
    "        feed = feedparser.parse(feed_url)\n",
    "        for entry in feed.entries:\n",
    "            articles.append({\n",
    "                \"source\": label,\n",
    "                \"url\": entry.link,\n",
    "                \"title\": entry.title,\n",
    "                \"published_at\": entry.published if \"published\" in entry else \"\",\n",
    "                \"content\": entry.get(\"summary\", \"\"),\n",
    "                \"platforms_mentioned\": [],\n",
    "            })\n",
    "    print(f\"→ Investing.com RSS: {len(articles)} articles fetched.\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00834093-1908-42c8-ba5c-717f733ef848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CRUNCHBASE FETCH ==========\n",
    "import requests, json\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "\n",
    "def fetch_crunchbase_sections():\n",
    "    \"\"\"\n",
    "    Scrape three Crunchbase News sections and deep‑fetch each\n",
    "    article’s JSON‑LD to extract a proper published_at and content.\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://news.crunchbase.com\"\n",
    "    sections = [\n",
    "        {\n",
    "            \"label\": \"Crunchbase News – Fintech [Scrape]\",\n",
    "            \"url\": f\"{BASE_URL}/sections/fintech-ecommerce/\",\n",
    "            \"keywords\": {\"lending\", \"credit\", \"finance\", \"regulation\", \"regulations\"},\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Crunchbase News – IPO [Scrape]\",\n",
    "            \"url\": f\"{BASE_URL}/sections/public/ipo/\",\n",
    "            \"keywords\": None,\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Crunchbase News – Seed Funding [Scrape]\",\n",
    "            \"url\": f\"{BASE_URL}/sections/seed/\",\n",
    "            \"keywords\": None,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    articles = []\n",
    "\n",
    "    for sec in sections:\n",
    "        section_resp = requests.get(sec[\"url\"], headers=headers)\n",
    "        section_resp.raise_for_status()\n",
    "        soup = BeautifulSoup(section_resp.text, \"lxml\")\n",
    "\n",
    "        # each H2 with a link is one article teaser on the section page\n",
    "        for h2 in soup.find_all(\"h2\"):\n",
    "            link_tag = h2.find(\"a\", href=True)\n",
    "            if not link_tag:\n",
    "                continue\n",
    "\n",
    "            title = link_tag.get_text(strip=True)\n",
    "            href  = link_tag[\"href\"]\n",
    "            url   = href if href.startswith(\"http\") else (BASE_URL + href)\n",
    "\n",
    "            # now deep‑fetch the article page\n",
    "            art = requests.get(url, headers=headers)\n",
    "            art.raise_for_status()\n",
    "            art_soup = BeautifulSoup(art.text, \"lxml\")\n",
    "\n",
    "            # find the JSON‑LD with \"@type\": \"NewsArticle\"\n",
    "            published_iso = \"\"\n",
    "            content_snip = \"\"\n",
    "            for script in art_soup.find_all(\"script\", type=\"application/ld+json\"):\n",
    "                try:\n",
    "                    data = json.loads(script.string)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "                # handle list or single object\n",
    "                if isinstance(data, list):\n",
    "                    # find the NewsArticle entry\n",
    "                    for entry in data:\n",
    "                        if entry.get(\"@type\") == \"NewsArticle\":\n",
    "                            data = entry\n",
    "                            break\n",
    "                if data.get(\"@type\") != \"NewsArticle\":\n",
    "                    continue\n",
    "\n",
    "                # extract publish date\n",
    "                dp = data.get(\"datePublished\") or data.get(\"uploadDate\")\n",
    "                if dp:\n",
    "                    try:\n",
    "                        # normalize to ISO 8601 UTC\n",
    "                        dt = parser.isoparse(dp)\n",
    "                        published_iso = dt.date().isoformat() \n",
    "                    except Exception:\n",
    "                        ppublished_iso = dp.split(\"T\")[0] if \"T\" in dp else dp\n",
    "                # extract a snippet: articleBody is full text, description is summary\n",
    "                content_snip = data.get(\"description\") or data.get(\"articleBody\",\"\")\n",
    "                break  # stop after first NewsArticle\n",
    "\n",
    "            # if JSON-LD failed, you could fallback to section‑page teaser\n",
    "            if not content_snip:\n",
    "                p = h2.find_next_sibling(\"p\")\n",
    "                content_snip = p.get_text(strip=True) if p else \"\"\n",
    "\n",
    "            # apply your keyword filter only on Fintech section\n",
    "            if sec[\"keywords\"]:\n",
    "                txt = (title + \" \" + content_snip).lower()\n",
    "                if not any(k in txt for k in sec[\"keywords\"]):\n",
    "                    continue\n",
    "\n",
    "            articles.append({\n",
    "                \"source\":    sec[\"label\"],\n",
    "                \"url\":       url,\n",
    "                \"title\":     title,\n",
    "                \"published_at\": published_iso,\n",
    "                \"content\":     content_snip,\n",
    "                \"platforms_mentioned\": [],\n",
    "            })\n",
    "\n",
    "    print(f\"→ Crunchbase News (all sections): {len(articles)} fetched.\")\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41cb3b0-4abf-4937-9981-1169d90db6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SAVE ==========\n",
    "# ── Compute a repo-relative data directory ──────────────────────────────────────\n",
    "# In Actions, cwd() will be /github/workspace; locally it'll be wherever you launch Jupyter.\n",
    "BASE_DIR = Path().cwd()\n",
    "SAVE_DIR = BASE_DIR / \"data\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def save_articles(articles):\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    filepath = SAVE_DIR / f\"news_{today}.json\"\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(articles, f, indent=2)\n",
    "    print(f\"✅ Saved {len(articles)} articles to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b93fa57d-9f11-42ed-a0ac-124d74edcd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from NewsAPI...\n",
      "→ NewsAPI: 99 articles fetched.\n",
      "Fetching Bloomberg RSS feeds...\n",
      "→ Bloomberg RSS: 180 articles fetched.\n",
      "Fetching from GNews (lending and credit)...\n",
      "→ GNews: 10 articles fetched.\n",
      "Fetching Investing.com RSS feeds...\n",
      "→ Investing.com RSS: 20 articles fetched.\n",
      "→ SEC Press Releases: 25 fetched.\n",
      "→ Crunchbase News (all sections): 24 fetched.\n",
      "✅ Saved 358 articles to /Users/florianterne/Documents/M.Sc DMBA/Consulting Project/exaloan_news_tracker/data/news_2025-04-22.json\n"
     ]
    }
   ],
   "source": [
    "# ========== RUN ==========\n",
    "newsapi_articles     = fetch_newsapi()\n",
    "rss_articles         = fetch_bloomberg_rss()\n",
    "gnews_articles       = fetch_gnews_financial_times()\n",
    "investing_articles   = fetch_investing_rss()\n",
    "sec_articles         = fetch_sec_press_releases()\n",
    "crunchbase_articles  = fetch_crunchbase_sections()\n",
    "\n",
    "all_articles = (\n",
    "    newsapi_articles\n",
    "  + rss_articles\n",
    "  + gnews_articles\n",
    "  + investing_articles\n",
    "  + sec_articles\n",
    "  + crunchbase_articles\n",
    ")\n",
    "\n",
    "if all_articles:\n",
    "    save_articles(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdaa72-ea9c-4c84-8168-ddff8487aa12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
