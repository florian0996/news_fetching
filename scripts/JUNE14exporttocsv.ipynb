{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc26d789-d235-4865-828b-0c1e30ddbf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enrichment complete: 'enriched_news.json' and 'enriched_news.csv' created.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Lists of entities for detection (lowercase)\n",
    "origination_platforms = [\n",
    "    \"acredius\", \"anodu\", \"biz2credit\", \"bondora\", \"bondster\", \"cashenable\", \"cg24\",\n",
    "    \"colectual\", \"conda\", \"crowd4cash\", \"crx\", \"evenfi\", \"fellow finance\", \"finbee\",\n",
    "    \"finomark\", \"flex funding\", \"fulfin\", \"funding partner\", \"geldvoorelkaar\", \"get income\",\n",
    "    \"goparity\", \"hive finance\", \"itf group\", \"klear lending\", \"kom group\", \"lend\",\n",
    "    \"lendahand\", \"lending club\", \"max crowdfund\", \"mozzeno\", \"raize\", \"savy\", \"spraypay\",\n",
    "    \"stately credit\", \"steward\", \"stockcrowd in\", \"tapline\", \"untapped global\",\n",
    "    \"vauraus\", \"winwinner\", \"wiseed\"\n",
    "]\n",
    "\n",
    "competitors = [\"dv01\", \"cardoai\", \"lendity\", \"i2invest\", \"crosslend\", \"alterest\"]\n",
    "\n",
    "fintech_funds = [\n",
    "    \"avellinia\", \"awi kmu darlehen\", \"castlelake\", \"channel capital\", \"fasanara\",\n",
    "    \"nordix\", \"scayl\", \"smart lenders\", \"tavis capital\", \"viola credit\", \"winyield\",\n",
    "    \"accial capital\", \"lendable inc.\", \"goldfinch\", \"northern arc capital\",\n",
    "    \"pollen street capital\", \"victory park capital\", \"ranger capital\", \"gli finance\",\n",
    "    \"prime meridian\", \"stone ridge\"\n",
    "]\n",
    "\n",
    "# Keywords for classification\n",
    "regulation_keywords = ['regulation', 'gesetz', 'bafin', 'aufsicht', 'gesetzgebung', 'compliance']\n",
    "platform_keywords = ['plattform', 'platform', 'credit', 'lending', 'neobank', 'fintech', 'origination']\n",
    "funding_keywords = ['funding', 'investment', 'capital', 'fund']\n",
    "partnership_keywords = ['partnership', 'collaboration', 'alliance', 'cooperation']\n",
    "insolvency_keywords = ['insolvency', 'restructuring', 'default', 'bankruptcy', 'liquidation', 'debt']\n",
    "\n",
    "exaloan_keywords = ['exaloan', 'creditshelf', 'scorechain']\n",
    "\n",
    "competitor_keywords = competitors  # can expand if needed\n",
    "\n",
    "# Normalize all entity lists for matching\n",
    "all_names = {\n",
    "    \"platforms\": origination_platforms,\n",
    "    \"competitors\": competitors,\n",
    "    \"funds\": fintech_funds,\n",
    "}\n",
    "\n",
    "def detect_entities(text):\n",
    "    text_lower = text.lower()\n",
    "    platforms_mentioned = [name for name in all_names[\"platforms\"] if name in text_lower]\n",
    "    competitors_mentioned = [name for name in all_names[\"competitors\"] if name in text_lower]\n",
    "    funds_mentioned = [name for name in all_names[\"funds\"] if name in text_lower]\n",
    "    companies_mentioned = []\n",
    "    if any(word in text_lower for word in exaloan_keywords):\n",
    "        companies_mentioned.append(\"exaloan\")\n",
    "    return platforms_mentioned, competitors_mentioned, funds_mentioned, companies_mentioned\n",
    "\n",
    "def classify_article(text):\n",
    "    text_lower = text.lower()\n",
    "    if any(word in text_lower for word in exaloan_keywords):\n",
    "        return 'exaloan_reputation'\n",
    "    elif any(word in text_lower for word in competitor_keywords):\n",
    "        return 'competitor'\n",
    "    elif any(word in text_lower for word in regulation_keywords):\n",
    "        return 'regulation'\n",
    "    elif any(word in text_lower for word in funding_keywords):\n",
    "        return 'funding'\n",
    "    elif any(word in text_lower for word in partnership_keywords):\n",
    "        return 'partnership'\n",
    "    elif any(word in text_lower for word in insolvency_keywords):\n",
    "        return 'insolvency_risk'\n",
    "    elif any(word in text_lower for word in platform_keywords):\n",
    "        return 'platform'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        label = 'positive'\n",
    "    elif polarity < -0.1:\n",
    "        label = 'negative'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "    return label, polarity\n",
    "\n",
    "def extract_keywords(text):\n",
    "    # Simple keyword extraction by splitting commas and spaces, filter out short words\n",
    "    raw_keywords = [kw.strip() for kw in text.lower().replace(',', ' ').split() if len(kw) > 3]\n",
    "    # Remove duplicates\n",
    "    return list(set(raw_keywords))\n",
    "\n",
    "# Load scraped news\n",
    "with open('all_news.json', 'r', encoding='utf-8') as f:\n",
    "    news_data = json.load(f)\n",
    "\n",
    "enriched_data = []\n",
    "\n",
    "for article in news_data:\n",
    "    content = article.get('content', '')\n",
    "    # Fix date: try published_at or fallback to published, else empty string\n",
    "    date_raw = article.get('published_at') or article.get('published') or ''\n",
    "    date = date_raw[:10] if len(date_raw) >= 10 else ''\n",
    "    title = article.get('title', '')\n",
    "    \n",
    "    platforms, competitors_mentioned, funds_mentioned, companies_mentioned = detect_entities(content + \" \" + title)\n",
    "    category = classify_article(content + \" \" + title)\n",
    "    sentiment_label, sentiment_score = get_sentiment(content)\n",
    "    keywords = extract_keywords(content + \" \" + title)\n",
    "    \n",
    "    insolvency_flag = any(word in content.lower() for word in insolvency_keywords)\n",
    "    \n",
    "    enriched_data.append({\n",
    "        \"date\": date,\n",
    "        \"source\": article.get('source', ''),\n",
    "        \"title\": title,\n",
    "        \"url\": article.get('url', ''),\n",
    "        \"category\": category,\n",
    "        \"sentiment_label\": sentiment_label,\n",
    "        \"sentiment_score\": sentiment_score,\n",
    "        \"platforms_mentioned\": platforms,\n",
    "        \"competitors_mentioned\": competitors_mentioned,\n",
    "        \"funds_mentioned\": funds_mentioned,\n",
    "        \"companies_mentioned\": companies_mentioned,\n",
    "        \"keywords\": keywords,\n",
    "        \"insolvency_risk\": insolvency_flag\n",
    "    })\n",
    "\n",
    "# Save enriched JSON\n",
    "with open('enriched_news.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(enriched_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Optionally save to CSV (flattening lists as comma-separated strings)\n",
    "csv_columns = [\n",
    "    \"date\", \"source\", \"title\", \"url\", \"category\", \"sentiment_label\", \"sentiment_score\",\n",
    "    \"platforms_mentioned\", \"competitors_mentioned\", \"funds_mentioned\", \"companies_mentioned\",\n",
    "    \"keywords\", \"insolvency_risk\"\n",
    "]\n",
    "\n",
    "with open('enriched_news.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "    for row in enriched_data:\n",
    "        row_csv = row.copy()\n",
    "        # Join lists into strings for CSV\n",
    "        row_csv[\"platforms_mentioned\"] = \", \".join(row[\"platforms_mentioned\"])\n",
    "        row_csv[\"competitors_mentioned\"] = \", \".join(row[\"competitors_mentioned\"])\n",
    "        row_csv[\"funds_mentioned\"] = \", \".join(row[\"funds_mentioned\"])\n",
    "        row_csv[\"companies_mentioned\"] = \", \".join(row[\"companies_mentioned\"])\n",
    "        row_csv[\"keywords\"] = \", \".join(row[\"keywords\"])\n",
    "        writer.writerow(row_csv)\n",
    "\n",
    "print(\"✅ Enrichment complete: 'enriched_news.json' and 'enriched_news.csv' created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
